{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing of next word prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rNZ5f2yOsRx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pickle"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "i-WOxj7VgvKN",
        "outputId": "1132933e-9bb1-4638-f4a1-9c8e13d7b9df"
      },
      "source": [
        "#Model Download\n",
        "url = 'https://drive.google.com/uc?id=1R-yacIxRx9GzRLt9ZJ9poZ9yqfpV_2ze'\n",
        "output = 'model1.h5'\n",
        "gdown.download(url, output, quiet=False) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R-yacIxRx9GzRLt9ZJ9poZ9yqfpV_2ze\n",
            "To: /content/model1.h5\n",
            "7.53MB [00:00, 11.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model1.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "HaWpx00ojTSG",
        "outputId": "6c690b62-61c2-4500-9c9f-b93dbea856d7"
      },
      "source": [
        "#Tokenizer Download\n",
        "token_url = 'https://drive.google.com/uc?id=178W72kj8x22hlGapG-YRyzYyAjagBM_G'\n",
        "output = 'tokenizer.pickle'\n",
        "gdown.download(token_url, output, quiet=False) \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=178W72kj8x22hlGapG-YRyzYyAjagBM_G\n",
            "To: /content/tokenizer.pickle\n",
            "100%|██████████| 253k/253k [00:00<00:00, 30.9MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tokenizer.pickle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOFpVTlbc7TL"
      },
      "source": [
        "#loading model\n",
        "model = load_model('model1.h5')\n",
        "\n",
        "# loading tokenizer\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2zyxW4blIE0"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "\n",
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.load(module_url)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I5u4LTUhPPN",
        "outputId": "203703e0-a4b5-4d7b-cab2-d83ed3636fbb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 128, 2)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128, 2)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 2)            8         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               67072     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 6393)              415545    \n",
            "=================================================================\n",
            "Total params: 622,465\n",
            "Trainable params: 622,333\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuTEkZ0CHPun"
      },
      "source": [
        "def Predict_Next_Words(text):\n",
        "  for i in range(3):\n",
        "        sequence = embed([text])\n",
        "        sequence = np.array(sequence)\n",
        "        \n",
        "        #preds = model.predict_classes(sequence)\n",
        "        preds=np.argmax(model.predict(sequence), axis=-1)\n",
        "        predicted_word = \"\"\n",
        "        #print(preds)\n",
        "        for key, value in tokenizer.word_index.items():\n",
        "            if value == preds:\n",
        "                predicted_word = key\n",
        "                break\n",
        "        \n",
        "\n",
        "  return predicted_word"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Qh34669bmzVX",
        "outputId": "006d95e7-5736-4ab7-d815-7868a4eca6e2"
      },
      "source": [
        "Predict_Next_Words('Please go')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[2]\n",
            "[2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6qf_M5IPyb"
      },
      "source": [
        "\"\"\"\n",
        "    We are testing our model and we will run the model\n",
        "    until the user decides to stop the script.\n",
        "    While the script is running we try and check if \n",
        "    the prediction can be made on the text. If no\n",
        "    prediction can be made we just continue.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#Input the sentence or phrase for predicition and press Enter. Stop the process by inputing 'stop'\n",
        "\n",
        "while(True):\n",
        "\n",
        "    text = input(\"Enter your line: \")\n",
        "    \n",
        "    if text == \"stop\":\n",
        "        print(\"Ending The Program.....\")\n",
        "        break\n",
        "    \n",
        "    else:\n",
        "      #print(text)\n",
        "      ans=Predict_Next_Words(text)\n",
        "      print(ans)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVxnD_WWIwoB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}